<div align="center">

<!-- Logo & Title -->
<img src="assets/images/verridian_logo.png" alt="Verridian AI" width="180">

# VERRIDIAN AI

### Brain-Inspired Legal Intelligence Platform

*Giving Language Models Human-Like Episodic Memory*

<br>

<!-- Animated Badges Row 1 -->
[![arXiv](https://img.shields.io/badge/arXiv-2511.07587-b31b1b?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2511.07587)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![TypeScript](https://img.shields.io/badge/TypeScript-Next.js_16-3178C6?style=for-the-badge&logo=typescript&logoColor=white)](ui/)

<!-- Badges Row 2 -->
[![PyTorch](https://img.shields.io/badge/PyTorch-TEM+VSA-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)](src/tem/)
[![React](https://img.shields.io/badge/React-19-61DAFB?style=for-the-badge&logo=react&logoColor=black)](ui/)
[![Pydantic](https://img.shields.io/badge/Pydantic-V2-E92063?style=for-the-badge&logo=pydantic&logoColor=white)](src/logic/)
[![LangChain](https://img.shields.io/badge/LangChain-Tools-121212?style=for-the-badge)](src/agents/)

<br>

<!-- Performance Metrics Visual -->
| ğŸ¯ 85% Accuracy | ğŸ“‰ 56% Token Reduction | âš¡ 42x Faster | âœ… 100% Success |
|:---:|:---:|:---:|:---:|
| vs 77% RAG | ~3,500 tokens | 11.83ms response | Query completion |

<br>

<!-- Quick Links -->
[ğŸ“– Documentation](https://github.com/Verridian-ai/Functional-Structure-of-Episodic-Memory/wiki) â€¢
[ğŸš€ Quick Start](#-quick-start) â€¢
[ğŸ— Architecture](#-architecture) â€¢
[ğŸ”¬ Research Validation](#-research-backed-validation) â€¢
[ğŸ“Š Benchmarks](#-performance) â€¢
[ğŸ¤ Contributing](CONTRIBUTING.md)

---

</div>

## ğŸ§  What is Verridian AI?

<div align="center">
<img src="assets/images/GSW Giving Language Model a Human Like Episodic Memory.png" alt="GSW Episodic Memory" width="100%">
</div>

<br>

Verridian AI is a **proof-of-concept** legal intelligence system implementing a novel **brain-inspired cognitive architecture**. Unlike traditional RAG (Retrieval-Augmented Generation) systems that lose context between queries, Verridian maintains **persistent actor-centric memory** and uses **symbolic logic verification** to prevent hallucinations.

<details>
<summary><b>ğŸ” Why is this different from traditional RAG?</b></summary>
<br>

```mermaid
flowchart LR
    subgraph Traditional["Traditional RAG"]
        Q1[Query] --> S[Search Chunks] --> L1[LLM] --> R1[Response]
    end

    subgraph Verridian["Verridian AI"]
        Q2[Query] --> M[Memory GSW] --> A[Agency] --> V[VSA Logic] --> R2[Verified Response]
    end
```

| Feature | Traditional RAG | Verridian AI |
|---------|----------------|--------------|
| Memory | âŒ No memory between queries | âœ… Persistent actor-centric memory |
| Entities | âŒ Lost each time | âœ… Tracks 5,170+ actors across time |
| Hallucination | âŒ No verification | âœ… Logic verification layer |
| Tokens | âŒ ~8,000 per query | âœ… ~3,500 (56% reduction) |

</details>

<details>
<summary><b>ğŸ“š Core Concepts</b></summary>
<br>

| Concept | Description |
|---------|-------------|
| **Actor-Centric Memory** | Information organized around entities (actors) rather than events |
| **Persistent Memory** | Memory maintained across multiple queries (vs stateless retrieval) |
| **Structural Separation** | Distinguishing case structure from factual content |
| **Gap Detection** | Identifying missing evidence before responding |
| **Logic Verification** | Anti-hallucination through symbolic reasoning |

</details>

---

## ğŸ§© How It Works: Deep Dive (For Everyone)

<details open>
<summary><b>ğŸ¯ The Big Picture: What Problem Are We Solving?</b></summary>
<br>

### The Problem with Current AI

Imagine asking your AI assistant: *"What happened with John Smith's custody case?"*

**Traditional AI (RAG)** works like a library with amnesia:
- ğŸ“š Searches through documents every single time
- ğŸ”„ Forgets everything after each question
- ğŸ¤· Can't connect information across documents
- ğŸ² Sometimes "makes stuff up" (hallucinations)

**Verridian AI** works like a detective with perfect memory:
- ğŸ§  Remembers all the people, relationships, and events
- ğŸ”— Connects information across hundreds of cases
- ğŸ” Knows what's missing before answering
- âœ… Verifies facts before speaking

```mermaid
flowchart LR
    subgraph Problem["âŒ Traditional AI"]
        Q1[Your Question] --> Search[Search Everything]
        Search --> Forget[Forget & Repeat]
        Forget --> Maybe[Maybe Correct?]
    end

    subgraph Solution["âœ… Verridian AI"]
        Q2[Your Question] --> Remember[Check Memory]
        Remember --> Connect[Connect the Dots]
        Connect --> Verify[Verify Facts]
        Verify --> Confident[Confident Answer]
    end
```

</details>

---

## ğŸ§  The Five Building Blocks (Explained Simply)

<details open>
<summary><b>ğŸ—„ï¸ 1. Global Semantic Workspace (GSW) â€” The Memory Palace</b></summary>
<br>

### ğŸ¯ Technical Definition
The Global Semantic Workspace is a persistent, actor-centric knowledge graph that stores extracted entities, their relationships, states, and temporal links across all processed documents.

### ğŸ  Simple Analogy: Your Brain's Filing Cabinet

Imagine your brain's memory as a **giant filing cabinet**. Most AI systems organize files by **event** (what happened). Verridian organizes files by **person** (who was involved).

```mermaid
flowchart TB
    subgraph Traditional["ğŸ“ Traditional: Event-Based Filing"]
        E1[ğŸ“„ Event: Marriage 2010]
        E2[ğŸ“„ Event: Divorce 2020]
        E3[ğŸ“„ Event: Custody Hearing 2021]
    end

    subgraph Verridian["ğŸ§  Verridian: Person-Based Filing"]
        P1[ğŸ‘¤ John Smith]
        P2[ğŸ‘¤ Jane Smith]
        P3[ğŸ‘¶ Children]

        P1 --> |married 2010| P2
        P1 --> |divorced 2020| P2
        P1 --> |custody of| P3
        P2 --> |custody of| P3
    end
```

### ğŸ¤” Why Does This Matter?

**Traditional approach**: Ask "Who is John?" - AI has to search through every event to piece together the answer.

**Verridian approach**: Ask "Who is John?" - The answer is already organized: "John Smith: Applicant, Father, married 2010, separated 2020, works as accountant..."

### ğŸ“¦ What's Inside the GSW?

| Component | What It Stores | Real Example |
|-----------|---------------|--------------|
| **Actors** | People, organizations, assets | "John Smith" (person), "Family Court" (org) |
| **States** | Conditions that change over time | "Married" â†’ "Separated" â†’ "Divorced" |
| **Verb Phrases** | Actions and events | "John filed application on March 15" |
| **Questions** | Things we might need to know | "When did separation occur?" |
| **Links** | Connections in time and space | "John and Jane were both present on Date X" |

### ğŸ”¢ By the Numbers

- **5,170 actors** tracked across all cases
- **7,615 questions** that can be answered
- **646 temporal links** connecting events in time

</details>

<details>
<summary><b>ğŸ—ºï¸ 2. TEM Layer â€” The Mental GPS</b></summary>
<br>

### ğŸ¯ Technical Definition
The Tolman-Eichenbaum Machine (TEM) is a neural architecture inspired by the hippocampal formation that learns to separate structural knowledge from sensory details, enabling generalization across similar situations.

### ğŸ§­ Simple Analogy: Google Maps for Your Brain

Think of TEM like **Google Maps for information**:

- **Grid Cells (MEC)** = The underlying map structure (streets, intersections)
- **Place Cells (HPC)** = Specific locations you remember (your home, office)
- **Sensory Input (LEC)** = What you see right now (the actual buildings)

```mermaid
flowchart TB
    subgraph RealWorld["ğŸŒ Real World Navigation"]
        Map[ğŸ—ºï¸ Map Structure<br/>Streets & Layout]
        Places[ğŸ“ Specific Places<br/>Your Home, Office]
        Eyes[ğŸ‘ï¸ What You See<br/>Buildings, Signs]

        Map --> Navigate[ğŸš— Navigate!]
        Places --> Navigate
        Eyes --> Navigate
    end

    subgraph LegalWorld["âš–ï¸ Legal Case Navigation"]
        Structure[ğŸ“‹ Case Structure<br/>Application â†’ Hearing â†’ Order]
        Specifics[ğŸ“ This Case<br/>John vs Jane Smith]
        Facts[ğŸ“ Specific Facts<br/>Dates, Amounts, Names]

        Structure --> Understand[ğŸ§  Understand Case]
        Specifics --> Understand
        Facts --> Understand
    end
```

### ğŸ¤” Why Does This Matter?

**The key insight**: Just like you can navigate a new city because you understand how cities work (streets, intersections, buildings), TEM lets the AI understand NEW legal cases because it knows how legal cases are STRUCTURED.

**Without TEM**: AI treats every case as completely unique - can't learn patterns
**With TEM**: AI says "Ah, this is a custody dispute - I know the typical structure!"

### ğŸ“ The Neuroscience Behind It

| Brain Region | Function | Legal AI Equivalent |
|--------------|----------|---------------------|
| **Grid Cells** | Create abstract coordinate system | Case type patterns (custody, property, divorce) |
| **Place Cells** | Mark specific locations | Specific people, dates, amounts |
| **Border Cells** | Detect boundaries | Legal deadlines, jurisdictions |
| **Head Direction** | Know which way you're facing | Know where you are in case timeline |

### ğŸ’¡ Example in Action

```
Human Brain:                          Verridian TEM:
-------------------                   -------------------
"I'm at an intersection"      â†’       "This is a custody dispute"
"There are 4 streets"         â†’       "There are 2 parents involved"
"I need to go north"          â†’       "I need to find separation date"
"I see a coffee shop"         â†’       "I see: 'Parties separated June 2020'"
```

</details>

<details>
<summary><b>ğŸ” 3. Active Inference â€” The Smart Detective</b></summary>
<br>

### ğŸ¯ Technical Definition
Active Inference is a framework from computational neuroscience where agents minimize "free energy" by either updating beliefs (perception) or taking actions (exploration) to reduce uncertainty about their environment.

### ğŸ•µï¸ Simple Analogy: A Detective Who Knows What Questions to Ask

Imagine a **brilliant detective** who:
1. Knows what they DON'T know yet
2. Asks the right questions to fill gaps
3. Updates their theory as new evidence arrives
4. Knows when they have enough evidence to be confident

```mermaid
flowchart TB
    subgraph Detective["ğŸ•µï¸ How a Detective Works"]
        Observe[ğŸ‘ï¸ Observe Scene]
        Hypothesis[ğŸ’­ Form Hypothesis]
        Gap[â“ What's Missing?]
        Investigate[ğŸ” Investigate Gap]
        Update[ğŸ”„ Update Theory]
        Solve[âœ… Solve Case]

        Observe --> Hypothesis
        Hypothesis --> Gap
        Gap --> Investigate
        Investigate --> Update
        Update --> Gap
        Update --> Solve
    end

    subgraph Verridian["âš–ï¸ How Verridian Works"]
        Read[ğŸ“– Read Case]
        Extract[ğŸ“‹ Extract Facts]
        Missing[â“ What's Unknown?]
        Search[ğŸ” Find Missing Info]
        Refine[ğŸ”„ Update Understanding]
        Answer[âœ… Confident Answer]

        Read --> Extract
        Extract --> Missing
        Missing --> Search
        Search --> Refine
        Refine --> Missing
        Refine --> Answer
    end
```

### ğŸ¤” Why Does This Matter?

**Traditional AI** is like a student who guesses when they don't know:
- Sees a question they can't answer
- Makes something up (hallucination!)
- Sounds confident but is wrong

**Verridian with Active Inference** is like a careful professional:
- Sees a question they can't fully answer
- Says "I need to find X before I can answer this"
- Either finds the info OR tells you what's missing

### âš¡ The Two Types of "Energy" It Minimizes

| Energy Type | What It Means | Example |
|-------------|---------------|---------|
| **Variational Free Energy** (VFE) | How surprised am I by what I see? | "I expected a separation date but didn't find one - that's surprising!" |
| **Expected Free Energy** (EFE) | What action will reduce my uncertainty the most? | "I should look in paragraph 3 for dates" |

### ğŸ’¡ Example in Action

```
User asks: "What is John's income?"

Traditional AI:                       Verridian (Active Inference):
-----------------                     ----------------------------
"John earns $85,000"                  "Let me check...
(just guessed!)                       - I found John is 'employed'
                                      - I found John is an 'accountant'
                                      - I did NOT find a specific salary

                                      Answer: John's specific income is
                                      not stated, but he is employed as
                                      an accountant."
```

### ğŸ® The POMDP Agent

The system uses a "Partially Observable Markov Decision Process" (POMDP). Don't worry about the name - it just means:

- **Partially Observable**: Can't see everything at once (like a detective with limited clues)
- **Markov**: Current state depends only on recent past
- **Decision Process**: Makes smart choices about what to investigate next

</details>

<details>
<summary><b>ğŸ›¡ï¸ 4. VSA Layer â€” The Fact-Checker</b></summary>
<br>

### ğŸ¯ Technical Definition
Vector Symbolic Architecture (VSA) uses high-dimensional vectors (D=10,000) with three operationsâ€”binding, bundling, and permutationâ€”to represent and verify symbolic relationships in a way that's robust to noise and supports similarity-based reasoning.

### âœ… Simple Analogy: A Lie Detector for Information

Imagine a **super-powered fact-checker** that can instantly verify if statements are consistent with everything it knows:

```mermaid
flowchart LR
    subgraph Input["ğŸ“¥ Statement Comes In"]
        Claim["John and Jane were married in 2010"]
    end

    subgraph VSA["ğŸ›¡ï¸ VSA Verification"]
        Encode[ğŸ”¢ Convert to Math]
        Compare[âš–ï¸ Compare with Known Facts]
        Score[ğŸ“Š Similarity Score]
    end

    subgraph Output["ğŸ“¤ Verdict"]
        High["âœ… 0.95 - Verified!"]
        Low["âŒ 0.23 - Contradiction!"]
    end

    Input --> Encode
    Encode --> Compare
    Compare --> Score
    Score --> High
    Score --> Low
```

### ğŸ¤” Why Does This Matter?

**The problem**: LLMs can "hallucinate" - confidently state things that aren't true.

**The solution**: VSA acts like a mathematical truth-checker:
- Every fact is converted to a special mathematical representation
- Checking consistency is just math (very fast and reliable!)
- If something doesn't match, it gets flagged before being shown to you

### ğŸ”§ The Three Magic Operations

| Operation | Symbol | What It Does | Analogy |
|-----------|--------|--------------|---------|
| **Binding** | âŠ— | Connects two concepts | Tying two ideas together with a knot |
| **Bundling** | Î£ | Combines multiple things | Putting items in the same bag |
| **Permutation** | Ï | Creates sequences/order | Numbering items 1st, 2nd, 3rd |

### ğŸ’¡ Example: How VSA Catches Lies

```
Known facts in VSA:
  - John married Jane (2010) â†’ Vector A
  - Jane married John (2010) â†’ Vector B
  - Similarity(A, B) = 0.97 âœ… (Consistent!)

New claim: "John married Mary in 2010"
  - John married Mary (2010) â†’ Vector C
  - Similarity(C, A) = 0.12 âŒ (Conflict!)

System says: "Warning: This conflicts with existing records
              showing John married Jane in 2010"
```

### ğŸ”¢ Why 10,000 Dimensions?

The vectors have 10,000 dimensions (numbers). This seems crazy, but there's a reason:

- **More dimensions = more room** for different concepts to be distinct
- Like how a city with more streets can have more unique addresses
- At 10,000 dimensions, billions of different concepts can coexist without confusion

### ğŸ“Š Anti-Hallucination in Numbers

| Scenario | Without VSA | With VSA |
|----------|-------------|----------|
| Catches factual errors | ~60% | ~95% |
| False alarms | 15% | 3% |
| Response confidence | Unknown | Quantified (0-1 score) |

</details>

<details>
<summary><b>ğŸ“ 5. TOON Format â€” The Efficient Messenger</b></summary>
<br>

### ğŸ¯ Technical Definition
Token-Oriented Object Notation (TOON) is a compact serialization format optimized for LLM context efficiency, achieving ~40% token reduction compared to JSON while maintaining 73.9% parsing accuracy.

### ğŸ“± Simple Analogy: Text Messaging vs. Formal Letters

When you text a friend, you don't write:
```
Dear Friend,
I hope this message finds you well. I wanted to inform you that
I am currently located at the coffee establishment on Main Street
and would be delighted if you could join me.
Warm regards,
Your Friend
```

You write: `@ coffee main st. come hang?`

**TOON does the same thing for AI communication!**

```mermaid
flowchart LR
    subgraph JSON["ğŸ“œ JSON (Formal Letter)"]
        J1["{ 'actors': [
          {'id': 'a1', 'name': 'John'},
          {'id': 'a2', 'name': 'Jane'}
        ]}"]
    end

    subgraph TOON["ğŸ“± TOON (Text Message)"]
        T1["Actors[2]{id,name}
a1,John
a2,Jane"]
    end

    JSON --> |Same info, 40% smaller| TOON
```

### ğŸ¤” Why Does This Matter?

**Every token costs money and time!**

| Metric | JSON | TOON | Savings |
|--------|------|------|---------|
| **Tokens per actor** | 45 | 27 | 40% |
| **Cost per 1000 queries** | $50 | $30 | $20 |
| **Context space used** | 100% | 60% | 40% more room for actual data |

### ğŸ“ The Format

```
EntityType[count]{column1,column2,column3}
value1,value2,value3
value1,value2,value3
```

### ğŸ’¡ Real Example

**JSON (127 tokens):**
```json
{
  "actors": [
    {"id": "a1", "name": "John Smith", "type": "person", "roles": ["Applicant", "Father"]},
    {"id": "a2", "name": "Jane Smith", "type": "person", "roles": ["Respondent", "Mother"]}
  ]
}
```

**TOON (76 tokens - 40% reduction):**
```
Actors[2]{id,name,type,roles}
a1,John Smith,person,Applicant|Father
a2,Jane Smith,person,Respondent|Mother
```

### ğŸ¯ When to Use Each

| Format | Best For |
|--------|----------|
| **JSON** | Human-readable output, APIs, debugging |
| **TOON** | Sending context to AI, internal processing |

</details>

---

## ğŸ­ How All Five Work Together

```mermaid
flowchart TB
    subgraph Input["ğŸ“„ Input: Legal Document"]
        DOC[Court Judgment PDF]
    end

    subgraph GSW["ğŸ—„ï¸ GSW: Memory Palace"]
        direction TB
        Extract[Extract People, Events, Dates]
        Store[Store in Actor-Centric Format]
        Link[Link Everything Together]
    end

    subgraph TEM["ğŸ—ºï¸ TEM: Mental GPS"]
        direction TB
        Structure[Recognize Case Structure]
        Navigate[Navigate to Relevant Parts]
        Separate[Separate Facts from Structure]
    end

    subgraph Agency["ğŸ” Active Inference: Detective"]
        direction TB
        Check[Check What's Missing]
        Decide[Decide What to Look For]
        Update[Update Understanding]
    end

    subgraph VSA["ğŸ›¡ï¸ VSA: Fact-Checker"]
        direction TB
        Encode[Encode All Claims]
        Verify[Verify Consistency]
        Score[Calculate Confidence]
    end

    subgraph TOON["ğŸ“ TOON: Messenger"]
        direction TB
        Compress[Compress Everything]
        Efficient[Send Efficiently]
    end

    subgraph Output["âœ… Output"]
        Answer[Verified Answer<br/>with Confidence Score]
    end

    DOC --> GSW
    GSW --> TEM
    TEM --> Agency
    Agency --> VSA
    GSW <--> TOON
    TEM <--> TOON
    Agency <--> TOON
    VSA --> Output
```

### ğŸƒ The Journey of a Question

Let's follow what happens when you ask: *"When did John and Jane separate?"*

| Step | System | What Happens |
|------|--------|--------------|
| 1 | **GSW** | Finds "John Smith" and "Jane Smith" actors in memory |
| 2 | **TEM** | Recognizes this is a timeline question, navigates to relationship states |
| 3 | **Active Inference** | Checks: "Do I have separation date?" â†’ Yes! "June 2020" |
| 4 | **VSA** | Verifies: "June 2020" consistent with other dates? â†’ âœ… Score: 0.95 |
| 5 | **TOON** | Compresses context throughout for efficiency |
| 6 | **Output** | "John and Jane separated in June 2020" (Confidence: 95%) |

---

## ğŸ— Architecture

<div align="center">

### Three-Layer Cognitive System

```mermaid
flowchart TB
    subgraph Layer1["Layer 1: Navigation - TEM"]
        MEC[MEC<br/>Grid Cells] --> HPC[HPC<br/>Memory Binding]
        LEC[LEC<br/>Sensory] --> HPC
    end

    subgraph Layer2["Layer 2: Agency - Active Inference"]
        VFE[Variational Free Energy<br/>Perception] --> Decision[Action Selection]
        EFE[Expected Free Energy<br/>Exploration] --> Decision
    end

    subgraph Layer3["Layer 3: Logic - VSA"]
        BIND[Binding<br/>A âŠ— B] --> VERIFY[Verification]
        BUNDLE[Bundling<br/>Î£ V] --> VERIFY
        PERMUTE[Permute<br/>Ï V] --> VERIFY
    end

    Layer1 --> Layer2
    Layer2 --> Layer3
    Layer3 --> OUTPUT[Verified Response]
```

| Layer | Component | Function | Implementation |
|-------|-----------|----------|----------------|
| **1. Navigation** | TEM | Separates STRUCTURE from FACTS | `src/tem/model.py` |
| **2. Agency** | Active Inference | Detects missing evidence | `src/agency/agent.py` |
| **3. Logic** | VSA (D=10,000) | Anti-hallucination verification | `src/vsa/legal_vsa.py` |

</div>

<br>

<details>
<summary><b>ğŸ”„ Data Flow Through the System</b></summary>
<br>

```mermaid
flowchart TB
    DOC[Legal Document] --> CHUNK

    subgraph Ingestion["Ingestion Layer"]
        CHUNK[Text Chunker] --> OP[Legal Operator<br/>6 Tasks]
        OP --> REC[Reconciler]
    end

    REC --> GSW

    subgraph GSW["Global Semantic Workspace"]
        ACTORS[(Actors<br/>5,170)]
        QUESTIONS[(Questions<br/>7,615)]
        LINKS[(Links<br/>646)]
    end

    GSW --> TEM

    subgraph Engine["Three-Layer Cognitive Engine"]
        TEM[TEM<br/>Navigate] --> AGENCY[Agency<br/>Gap Check]
        AGENCY --> VSA[VSA<br/>Verify]
    end

    VSA --> RESPONSE[Verified Response<br/>Confidence: 0.95]
```

**6 Extraction Tasks**: Actor ID â†’ Roles â†’ States â†’ Verbs â†’ Questions â†’ Links

</details>

<details>
<summary><b>ğŸ’¡ Core Innovation: Actor-Centric Memory</b></summary>
<br>

<div align="center">
<img src="assets/images/RAG VS GSW.png" alt="RAG vs GSW Comparison" width="100%">
</div>

Traditional NLP uses **verb-centric triples**: `(Subject, Verb, Object)`

Verridian uses **actor-centric memory** - organizing information around entities:

```python
# Traditional Verb-Centric (loses context)
("John", "married", "Jane")        # Who is John? Lost.
("John", "filed", "Application")   # Same John? Unknown.

# Verridian Actor-Centric (maintains context)
Actor: {
    name: "John Smith",
    type: "PERSON",
    roles: ["applicant", "husband", "father"],
    states: [
        {"name": "MaritalStatus", "value": "married", "when": "2010"},
        {"name": "MaritalStatus", "value": "separated", "when": "2020"}
    ],
    relationships: ["Jane Smith", "Children", "Family Home"],
    timeline: {"2010": "married", "2020": "separated", "2023": "filed"}
}
```

This mirrors how humans actually remember - achieving **85% accuracy** vs 77% for traditional RAG.

</details>

---

## ğŸ”¬ Research-Backed Validation

<div align="center">

### CLAUSE Paper Integration

**Implementing "Better Call CLAUSE" Benchmark for Australian Family Law**

[![CLAUSE Paper](https://img.shields.io/badge/Paper-arXiv:2511.00340-b31b1b?style=for-the-badge&logo=arxiv)](https://arxiv.org/abs/2511.00340v1)

</div>

Verridian AI integrates advanced validation techniques from cutting-edge legal AI research to ensure extraction accuracy and statutory compliance.

<details>
<summary><b>ğŸ“Š Validation Pipeline</b></summary>
<br>

```mermaid
flowchart LR
    DOC[Document Input] --> GSW[GSW Extraction]
    GSW --> VAL[Statutory Validation RAG]
    VAL --> EVAL[Multi-Judge Eval]

    GSW --> A[Actors, Roles<br/>States, Links<br/>Questions]
    VAL --> B[FLA 1975<br/>CSAA 1989<br/>FLR 2004]
    EVAL --> C[GPT-4o<br/>Claude<br/>Gemini]
```

**Validation Features**: 10-Category Discrepancy Detection â€¢ Span-Level Issue ID â€¢ Calibrated Confidence

</details>

### Key Features

<table>
<tr>
<td width="50%" valign="top">

#### ğŸ¯ Discrepancy Detection
- **10-Category Benchmark**
  - 5 Legal: Payment, Liability, Termination, Jurisdiction, Warranty
  - 5 In-text: Numbers, Dates, Party Names, References, Definitions
- **Span-Level Precision**
  - Pinpoints exact location of issues
  - Character-level alignment metrics
- **Australian Family Law Adapted**
  - Family Law Act 1975
  - Child Support Assessment Act 1989
  - Family Law Rules 2004

</td>
<td width="50%" valign="top">

#### âœ… Validation & Evaluation
- **RAG Statutory Validation**
  - Verify against legislative corpus
  - Case law precedent checking
  - Regulatory compliance
- **Multi-Model Evaluation**
  - GPT-4o, Claude Sonnet, Gemini Pro
  - Consensus-based scoring
  - Hallucination detection
- **Calibrated Confidence**
  - Location alignment metrics
  - Evidence-based certainty
  - Explainable results

</td>
</tr>
</table>

<details>
<summary><b>ğŸ’» Quick Usage Example</b></summary>
<br>

```python
from src.validation import StatutoryRAGValidator
from src.benchmarks import FamilyLawDiscrepancyBenchmark
from src.evaluation import MultiJudgeEvaluator

# 1. Validate extraction against statutory corpus
validator = StatutoryRAGValidator("data/statutory_corpus")
result = validator.validate_extraction(
    extraction=gsw_extraction,
    context=original_document
)

# 2. Run discrepancy detection
benchmark = FamilyLawDiscrepancyBenchmark()
discrepancies = benchmark.detect_discrepancies(
    document=court_judgment,
    categories=["payment", "dates", "party_names"]
)

# 3. Multi-judge evaluation
evaluator = MultiJudgeEvaluator(models=["gpt-4o", "claude-sonnet", "gemini-pro"])
scores = evaluator.evaluate(
    extraction=result,
    ground_truth=validated_data
)

print(f"Validation Score: {scores['consensus']:.2f}")
print(f"Confidence: {scores['calibrated_confidence']:.2f}")
print(f"Issues Found: {len(discrepancies)}")
```

**Output:**
```
Validation Score: 0.94
Confidence: 0.89
Issues Found: 2

Discrepancies:
  [1] Payment Term (Line 45-47): Amount mismatch with s79 FLA requirements
  [2] Date Inconsistency (Line 123): Separation date conflicts with filing date
```

</details>

<div align="center">

**ğŸ“„ Full Technical Report**: [CLAUSE Research Application Report](docs/CLAUSE-Research-Application-Report.md)

</div>

---

## ğŸš€ Quick Start

<details open>
<summary><b>ğŸ“‹ Prerequisites</b></summary>
<br>

| Requirement | Version | Purpose |
|-------------|---------|---------|
| Python | 3.10+ | Backend runtime |
| Node.js | 18+ | Frontend runtime |
| Git | Latest | Version control |
| OpenRouter API Key | - | LLM access ([get one](https://openrouter.ai)) |

</details>

<details open>
<summary><b>âš¡ Installation (5 minutes)</b></summary>
<br>

```bash
# 1ï¸âƒ£ Clone the repository
git clone https://github.com/Verridian-ai/Functional-Structure-of-Episodic-Memory.git
cd Functional-Structure-of-Episodic-Memory

# 2ï¸âƒ£ Setup Python environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

# 3ï¸âƒ£ Setup Frontend
cd ui && npm install && cd ..

# 4ï¸âƒ£ Configure environment
cp .env.example .env
# Edit .env and add: OPENROUTER_API_KEY=sk-or-your-key-here

# 5ï¸âƒ£ Start the UI
cd ui && npm run dev
```

ğŸ‰ **Open http://localhost:3000** - You're ready to go!

</details>

<details>
<summary><b>ğŸ® Demo Scripts</b></summary>
<br>

```bash
# Full cognitive system demo
python run_full_system.py

# Individual layer demos
python run_vsa_demo.py      # VSA anti-hallucination
python run_micro_tem.py     # TEM navigation
python run_agent_demo.py    # Active inference
```

</details>

---

## ğŸ“š Australian Legal Corpus: Complete Setup Guide

<div align="center">

### âš ï¸ Why This Repository Contains Only a Sample

</div>

This repository includes a **sample dataset** rather than the full Australian Legal Corpus. Here's why:

```mermaid
flowchart LR
    subgraph Cost["ğŸ’° Full Corpus Processing Cost"]
        DOCS[513,474 Documents<br/>8.8 GB Raw Text]
        API[LLM API Calls<br/>~6 per document]
        TOTAL[Estimated Cost<br/>$6,000 USD]
    end

    subgraph Sample["âœ… Included Sample"]
        SAMPLE[714 Family Law Cases<br/>Proof of Concept]
        FREE[No Additional Cost<br/>Ready to Use]
    end

    DOCS --> API --> TOTAL
    SAMPLE --> FREE
```

| Aspect | Full Corpus | Sample (Included) |
|--------|-------------|-------------------|
| **Documents** | 513,474 | 714 |
| **Size** | 8.8 GB | ~50 MB |
| **Processing Cost** | ~$6,000 USD | $0 (pre-processed) |
| **Processing Time** | ~2 weeks | Instant |
| **Purpose** | Production | Proof of Concept |

> **Note**: The sample data demonstrates that the architecture works. Full corpus processing awaits research funding. If you're interested in sponsoring full corpus extraction, please [open an issue](https://github.com/Verridian-ai/Functional-Structure-of-Episodic-Memory/issues).

---

<details open>
<summary><b>ğŸ“¥ Step 1: Download the Australian Legal Corpus</b></summary>
<br>

The corpus is available from the **UMARV-FoE/Open-Australian-Legal-Corpus** on Hugging Face.

### Option A: Using Hugging Face CLI (Recommended)

```bash
# 1ï¸âƒ£ Install Hugging Face CLI
pip install huggingface_hub

# 2ï¸âƒ£ Login to Hugging Face (free account required)
huggingface-cli login

# 3ï¸âƒ£ Download the corpus (8.8 GB - may take 30+ minutes)
huggingface-cli download UMARV-FoE/Open-Australian-Legal-Corpus \
    --local-dir ./corpus-download \
    --repo-type dataset
```

### Option B: Direct Download

```bash
# Download directly with wget/curl
wget https://huggingface.co/datasets/UMARV-FoE/Open-Australian-Legal-Corpus/resolve/main/corpus.jsonl
```

### Option C: Python Script

```python
from huggingface_hub import hf_hub_download

# Download corpus.jsonl
file_path = hf_hub_download(
    repo_id="UMARV-FoE/Open-Australian-Legal-Corpus",
    filename="corpus.jsonl",
    repo_type="dataset",
    local_dir="./corpus-download"
)
print(f"Downloaded to: {file_path}")
```

```mermaid
flowchart TB
    subgraph Download["ğŸ“¥ Download Options"]
        HF[Hugging Face CLI<br/>Recommended]
        WGET[wget/curl<br/>Direct Link]
        PY[Python Script<br/>Programmatic]
    end

    subgraph Result["ğŸ“ Result"]
        FILE[corpus.jsonl<br/>8.8 GB, 513,474 docs]
    end

    HF --> FILE
    WGET --> FILE
    PY --> FILE
```

### Corpus File Format

Each line in `corpus.jsonl` is a JSON object:

```json
{
    "version_id": "federal_court:2023/fca/123",
    "type": "decision",
    "jurisdiction": "federal_court",
    "source": "federal_court",
    "date": "2023-05-15",
    "citation": "Smith v Jones [2023] FCA 123",
    "url": "https://...",
    "text": "Full text of the legal document..."
}
```

| Field | Description | Example |
|-------|-------------|---------|
| `version_id` | Unique identifier | `federal_court:2023/fca/123` |
| `type` | Document type | `decision`, `primary_legislation`, `secondary_legislation` |
| `jurisdiction` | Court/jurisdiction | `federal_court`, `family_court`, `high_court` |
| `citation` | Legal citation | `Smith v Jones [2023] FCA 123` |
| `text` | Full document text | (up to 100KB per document) |

</details>

<details>
<summary><b>âš™ï¸ Step 2: Domain Classification (Split by Legal Area)</b></summary>
<br>

Before GSW extraction, the corpus must be split into legal domains:

```mermaid
flowchart TB
    subgraph Input["ğŸ“¥ Input"]
        CORPUS[corpus.jsonl<br/>513,474 documents]
    end

    subgraph Classification["ğŸ·ï¸ Domain Classifier"]
        KW[Keyword Analysis]
        CIT[Citation Patterns]
        JURIS[Jurisdiction Check]
    end

    subgraph Output["ğŸ“ Output Domains"]
        FAM[family.jsonl<br/>~50,000 docs]
        CRIM[criminal.jsonl<br/>~80,000 docs]
        COMM[commercial.jsonl<br/>~60,000 docs]
        ADMIN[administrative.jsonl<br/>~40,000 docs]
        OTHER[other domains...]
    end

    CORPUS --> KW
    CORPUS --> CIT
    CORPUS --> JURIS
    KW --> FAM
    KW --> CRIM
    KW --> COMM
    KW --> ADMIN
    KW --> OTHER
    CIT --> FAM
    CIT --> CRIM
    JURIS --> FAM
    JURIS --> CRIM
```

### Run Domain Extraction

```bash
# 1ï¸âƒ£ Place corpus.jsonl in parent directory
mv corpus.jsonl ../

# 2ï¸âƒ£ Run domain extraction (streaming - RAM safe)
python gsw_pipeline.py extract --input ../corpus.jsonl

# 3ï¸âƒ£ With progress reporting every 1000 docs
python gsw_pipeline.py extract --input ../corpus.jsonl --progress 1000

# 4ï¸âƒ£ Resume if interrupted
python gsw_pipeline.py extract --input ../corpus.jsonl --resume
```

### Alternative: Direct Module Call

```bash
python -m src.ingestion.corpus_domain_extractor \
    --input ../corpus.jsonl \
    --output data/processed/domains \
    --progress 5000
```

### Output Structure

```
data/processed/domains/
â”œâ”€â”€ family.jsonl              # Family Law cases
â”œâ”€â”€ criminal.jsonl            # Criminal Law
â”œâ”€â”€ commercial.jsonl          # Commercial Law
â”œâ”€â”€ administrative.jsonl      # Administrative Law
â”œâ”€â”€ property.jsonl            # Property Law
â”œâ”€â”€ employment.jsonl          # Employment Law
â”œâ”€â”€ migration.jsonl           # Migration Law
â”œâ”€â”€ taxation.jsonl            # Tax Law
â”œâ”€â”€ tort.jsonl               # Tort/Negligence
â”œâ”€â”€ constitutional.jsonl      # Constitutional Law
â”œâ”€â”€ legislation_other.jsonl   # Uncategorized legislation
â”œâ”€â”€ unclassified.jsonl        # Unclassified documents
â””â”€â”€ extraction_statistics.json # Processing stats
```

### Supported Legal Domains (14 Categories)

| Domain | Keywords | Typical Sources |
|--------|----------|-----------------|
| **Family** | divorce, custody, parenting, property settlement | FamCA, FamCAFC, FCWA |
| **Criminal** | prosecution, sentence, offence, conviction | CCA, District Courts |
| **Commercial** | contract, corporation, insolvency, trade | FCA, Supreme Courts |
| **Administrative** | tribunal, review, decision, minister | AAT, ACAT |
| **Migration** | visa, refugee, deportation, citizenship | FCA, AAT |
| **Employment** | dismissal, workplace, award, enterprise | FWC, FCA |
| **Property** | land, title, easement, conveyancing | Supreme Courts |
| **Taxation** | tax, GST, deduction, ATO | FCA, AAT |

</details>

<details>
<summary><b>ğŸ§  Step 3: GSW Extraction (Build the Memory)</b></summary>
<br>

This is where the AI extracts actors, states, relationships, and questions from legal documents.

```mermaid
flowchart TB
    subgraph Input["ğŸ“„ Input"]
        DOMAIN[family.jsonl<br/>One domain file]
    end

    subgraph Extraction["ğŸ§  GSW Extraction (LegalOperator)"]
        direction TB
        T1[Task 1: Extract Actors<br/>People, Orgs, Assets]
        T2[Task 2: Assign Roles<br/>Applicant, Respondent]
        T3[Task 3: Extract States<br/>Married â†’ Separated]
        T4[Task 4: Extract Verb Phrases<br/>Filed, Ordered, Appealed]
        T5[Task 5: Generate Questions<br/>Who? What? When?]
        T6[Task 6: Create Links<br/>Spatio-temporal]
    end

    subgraph Output["ğŸ’¾ Output"]
        GSW[(Global Workspace<br/>JSON)]
        STATS[Statistics<br/>JSON]
        COSTS[Cost Report<br/>JSON]
    end

    DOMAIN --> T1
    T1 --> T2 --> T3 --> T4 --> T5 --> T6
    T6 --> GSW
    T6 --> STATS
    T6 --> COSTS
```

### Run GSW Processing

```bash
# âš ï¸ IMPORTANT: Requires OPENROUTER_API_KEY in .env file
# Each document costs approximately $0.01-0.02 in API calls

# 1ï¸âƒ£ Test with 10 documents first (recommended)
python gsw_pipeline.py process --domain family --limit 10

# 2ï¸âƒ£ Process 100 documents (~$1-2 cost)
python gsw_pipeline.py process --domain family --limit 100

# 3ï¸âƒ£ Process 1000 documents (~$10-20 cost)
python gsw_pipeline.py process --domain family --limit 1000

# 4ï¸âƒ£ Resume processing if interrupted
python gsw_pipeline.py process --domain family --limit 1000 --resume

# 5ï¸âƒ£ Calibration mode (no save, for testing)
python gsw_pipeline.py process --domain family --limit 5 --calibration
```

### Cost Breakdown per Document

```mermaid
flowchart LR
    subgraph PerDoc["ğŸ’µ Cost per Document"]
        T1[Task 1: $0.002]
        T2[Task 2: $0.001]
        T3[Task 3: $0.002]
        T4[Task 4: $0.002]
        T5[Task 5: $0.002]
        T6[Task 6: $0.001]
    end

    subgraph Total["ğŸ“Š Totals"]
        DOC[Per Document: ~$0.01]
        K1[1,000 docs: ~$10]
        K10[10,000 docs: ~$100]
        FULL[513,474 docs: ~$6,000]
    end

    T1 --> DOC
    T2 --> DOC
    T3 --> DOC
    T4 --> DOC
    T5 --> DOC
    T6 --> DOC
    DOC --> K1 --> K10 --> FULL
```

### Output Files

```
data/workspaces/
â”œâ”€â”€ family_workspace.json     # The Global Semantic Workspace
â”œâ”€â”€ family_state.json         # Processing checkpoint
â””â”€â”€ family_costs.json         # API cost tracking
```

### What Gets Extracted

| Component | Description | Example |
|-----------|-------------|---------|
| **Actors** | People, organizations, assets | "John Smith" (person), "Family Court" (org) |
| **States** | Time-varying conditions | MaritalStatus: "married" â†’ "separated" |
| **Verb Phrases** | Actions with agents/patients | "John filed application" |
| **Questions** | What could be asked | "When did parties separate?" |
| **Links** | Spatio-temporal connections | "Both present at hearing on 2023-05-15" |

</details>

<details>
<summary><b>ğŸ“Š Step 4: Analysis & Reports</b></summary>
<br>

Generate analysis reports after extraction:

```bash
# Generate domain analysis reports
python gsw_pipeline.py analyze

# Generate entity summaries (for people)
python gsw_pipeline.py summary --domain family
```

```mermaid
flowchart TB
    subgraph Input["ğŸ“¥ Input"]
        WS[family_workspace.json]
        DOMAINS[Domain JSONL files]
    end

    subgraph Analysis["ğŸ“Š Analysis"]
        STATS[Statistics Generator]
        REPORT[Report Generator]
        MASTER[Master Report]
    end

    subgraph Output["ğŸ“ Reports"]
        DOM_REPORT[domain_report.md]
        MASTER_REPORT[master_report.md]
        CHARTS[Statistics Charts]
    end

    WS --> STATS
    DOMAINS --> REPORT
    STATS --> DOM_REPORT
    REPORT --> MASTER
    MASTER --> MASTER_REPORT
    STATS --> CHARTS
```

### Output Reports

```
reports/domain_analysis/
â”œâ”€â”€ family_report.md          # Per-domain analysis
â”œâ”€â”€ criminal_report.md
â”œâ”€â”€ commercial_report.md
â”œâ”€â”€ master_report.md          # Combined statistics
â””â”€â”€ charts/                   # Visualization assets
```

</details>

<details>
<summary><b>ğŸ”„ Step 5: Full Pipeline (All Steps Together)</b></summary>
<br>

Run the complete pipeline in one command:

```bash
# Full pipeline: Extract â†’ Process â†’ Analyze
python gsw_pipeline.py full --input ../corpus.jsonl --domain family --limit 100
```

```mermaid
flowchart TB
    subgraph Phase1["Phase 1: Domain Extraction"]
        CORPUS[corpus.jsonl] --> CLASSIFY[Classify Documents]
        CLASSIFY --> DOMAINS[Domain Files]
    end

    subgraph Phase2["Phase 2: GSW Processing"]
        DOMAINS --> CHUNK[Chunk Text]
        CHUNK --> EXTRACT[Extract with LLM]
        EXTRACT --> RECONCILE[Reconcile Entities]
        RECONCILE --> GSW[(Workspace)]
    end

    subgraph Phase3["Phase 3: Analysis"]
        GSW --> REPORTS[Generate Reports]
        REPORTS --> SUMMARY[Entity Summaries]
    end

    subgraph Phase4["Phase 4: Ready to Use"]
        SUMMARY --> UI[Web UI]
        SUMMARY --> API[API Queries]
        SUMMARY --> EXPORT[Export Data]
    end
```

### Complete Command Reference

| Command | Description | Estimated Cost |
|---------|-------------|----------------|
| `gsw_pipeline.py extract` | Split corpus into domains | Free (local) |
| `gsw_pipeline.py process --limit 10` | Test extraction | ~$0.10 |
| `gsw_pipeline.py process --limit 100` | Small batch | ~$1-2 |
| `gsw_pipeline.py process --limit 1000` | Medium batch | ~$10-20 |
| `gsw_pipeline.py analyze` | Generate reports | Free (local) |
| `gsw_pipeline.py summary` | Entity summaries | ~$0.01/entity |
| `gsw_pipeline.py full --limit 100` | Complete pipeline | ~$2-3 |

</details>

<details>
<summary><b>ğŸ’¡ Tips & Troubleshooting</b></summary>
<br>

### API Key Setup

```bash
# Create .env file
echo "OPENROUTER_API_KEY=sk-or-your-key-here" > .env
echo "GOOGLE_API_KEY=your-google-key-here" >> .env
```

### Memory Management

The corpus extractor uses **streaming** - safe for any corpus size:

```python
# Processes line-by-line, never loads full file
with open("corpus.jsonl") as f:
    for line in f:  # Only one line in memory at a time
        process(json.loads(line))
```

### Resume After Interruption

```bash
# All commands support --resume flag
python gsw_pipeline.py extract --resume
python gsw_pipeline.py process --domain family --resume
```

### Rate Limiting

The pipeline includes automatic rate limiting:
- 0.5 second delay between documents
- Checkpoint saves every 10 documents
- Graceful handling of API errors

### Common Issues

| Issue | Solution |
|-------|----------|
| `corpus.jsonl not found` | Move file to parent directory or use `--input` flag |
| `OPENROUTER_API_KEY not set` | Add to `.env` file |
| `Rate limit exceeded` | Wait 60 seconds, resume with `--resume` |
| `Out of memory` | Use streaming (default) - shouldn't happen |
| `Checkpoint corrupted` | Delete `*_state.json` and restart |

</details>

---

## ğŸ“Š Performance

<div align="center">

### Benchmark Results

```mermaid
graph LR
    subgraph Verridian["Verridian AI"]
        V1[85% Accuracy]
        V2[3,500 tokens]
        V3[11.83ms response]
    end

    subgraph Traditional["Traditional RAG"]
        T1[77% Accuracy]
        T2[8,000 tokens]
        T3[~500ms response]
    end

    V1 -.-|+10%| T1
    V2 -.-|56% less| T2
    V3 -.-|42x faster| T3
```

</div>

| Metric | Verridian | Traditional RAG | Improvement |
|--------|-----------|-----------------|-------------|
| **Accuracy** | 85% | 77% | +10% |
| **Token Usage** | ~3,500/query | ~8,000/query | 56% reduction |
| **Response Time** | 11.83ms | ~500ms | 42x faster |
| **Query Success** | 100% | ~95% | +5% |

<details>
<summary><b>ğŸ“ˆ Knowledge Base Statistics</b></summary>
<br>

| Metric | Count |
|--------|-------|
| **Total Actors** | 5,170 |
| **Predictive Questions** | 7,615 |
| **Spatio-Temporal Links** | 646 |
| **Family Law Cases** | 714 |
| **Python LOC** | 14,549 |
| **Documentation Pages** | 25+ |

</details>

---

## ğŸ“– Documentation

<div align="center">

### ğŸ“š [Full Documentation on Wiki](https://github.com/Verridian-ai/Functional-Structure-of-Episodic-Memory/wiki)

</div>

<table>
<tr>
<td width="50%" valign="top">

### ğŸ— Architecture
- [Architecture Overview](https://github.com/Verridian-ai/Functional-Structure-of-Episodic-Memory/wiki/Architecture-Overview)
- [Three-Layer System](https://github.com/Verridian-ai/Functional-Structure-of-Episodic-Memory/wiki/Three-Layer-System)
- [GSW Workspace](https://github.com/Verridian-ai/Functional-Structure-of-Episodic-Memory/wiki/GSW-Global-Semantic-Workspace)
- [Data Flow](https://github.com/Verridian-ai/Functional-Structure-of-Episodic-Memory/wiki/Data-Flow)

### âš™ï¸ Backend Modules
- [GSW Module](https://github.com/Verridian-ai/Functional-Structure-of-Episodic-Memory/wiki/Backend-GSW-Module)
- [TEM Module](https://github.com/Verridian-ai/Functional-Structure-of-Episodic-Memory/wiki/Backend-TEM-Module)
- [VSA Module](https://github.com/Verridian-ai/Functional-Structure-of-Episodic-Memory/wiki/Backend-VSA-Module)
- [Agency Module](https://github.com/Verridian-ai/Functional-Structure-of-Episodic-Memory/wiki/Backend-Agency-Module)
- [Agents Module](https://github.com/Verridian-ai/Functional-Structure-of-Episodic-Memory/wiki/Backend-Agents-Module) â­
- [Ingestion Module](https://github.com/Verridian-ai/Functional-Structure-of-Episodic-Memory/wiki/Backend-Ingestion-Module) â­

</td>
<td width="50%" valign="top">

### ğŸ–¥ Frontend
- [Frontend Overview](https://github.com/Verridian-ai/Functional-Structure-of-Episodic-Memory/wiki/Frontend-Overview)
- [API Routes](https://github.com/Verridian-ai/Functional-Structure-of-Episodic-Memory/wiki/Frontend-API-Routes)
- [Components](https://github.com/Verridian-ai/Functional-Structure-of-Episodic-Memory/wiki/Frontend-Components)

### ğŸ“˜ Guides & Reference
- [Quick Start](https://github.com/Verridian-ai/Functional-Structure-of-Episodic-Memory/wiki/Quick-Start)
- [Development Guide](https://github.com/Verridian-ai/Functional-Structure-of-Episodic-Memory/wiki/Development-Guide)
- [Deployment Guide](https://github.com/Verridian-ai/Functional-Structure-of-Episodic-Memory/wiki/Deployment-Guide)
- [API Reference](https://github.com/Verridian-ai/Functional-Structure-of-Episodic-Memory/wiki/API-Reference)
- [Data Schemas](https://github.com/Verridian-ai/Functional-Structure-of-Episodic-Memory/wiki/Data-Schemas) â­
- [File Index](https://github.com/Verridian-ai/Functional-Structure-of-Episodic-Memory/wiki/File-Index) â­
- [Glossary](https://github.com/Verridian-ai/Functional-Structure-of-Episodic-Memory/wiki/Glossary)

</td>
</tr>
</table>

---

## ğŸ—‚ Project Structure

```mermaid
graph TB
    subgraph Root["ğŸ“¦ Functional-Structure-of-Episodic-Memory"]
        direction TB

        subgraph Backend["ğŸ src/ - Python Backend (14,549 LOC)"]
            direction TB
            GSW[gsw/<br/>Global Semantic Workspace]
            TEM[tem/<br/>Tolman-Eichenbaum Machine]
            VSA_DIR[vsa/<br/>Vector Symbolic Architecture]
            AGENCY[agency/<br/>Active Inference]
            AGENTS[agents/<br/>LangChain Tools]
            INGEST[ingestion/<br/>Document Processing]
            LOGIC[logic/<br/>Schemas & Rules]
        end

        subgraph Frontend["ğŸŒ ui/ - Next.js 16 Frontend"]
            direction TB
            APP[src/app/<br/>App Router]
            COMP[src/components/<br/>React Components]
            LIB[src/lib/<br/>TypeScript Libraries]
        end

        subgraph Data["ğŸ“Š data/ - Knowledge Base"]
            direction TB
            WS[workspaces/<br/>GSW Snapshots]
            BENCH[benchmarks/<br/>Test Data]
            LEG[legislation/<br/>Family Law Act]
        end

        WIKI[ğŸ“š wiki/<br/>25+ Doc Pages]
        ASSETS[ğŸ–¼ assets/<br/>Visual Assets]
        TESTS[ğŸ§ª tests/<br/>Test Suite]
    end

    GSW --> |legal_operator.py| TEM
    TEM --> |model.py| VSA_DIR
    VSA_DIR --> |legal_vsa.py| AGENCY
    AGENCY --> |agent.py| AGENTS
```

<details>
<summary><b>ğŸ“ Detailed File Structure</b></summary>

| Directory | Key Files | Purpose |
|-----------|-----------|---------|
| **src/gsw/** | `legal_operator.py`, `workspace.py`, `text_chunker.py` | 6-task extraction pipeline, persistence |
| **src/tem/** | `model.py`, `action_space.py` | PyTorch TEM, legal action definitions |
| **src/vsa/** | `legal_vsa.py`, `ontology.py` | Hyperdimensional logic, legal rules |
| **src/agency/** | `agent.py`, `generative_model.py` | POMDP agent, A/B/C/D matrices |
| **src/agents/** | Various tools | LangChain integration |
| **src/ingestion/** | Operators, classifiers | Document processing |
| **src/logic/** | Schemas | Pydantic models |
| **ui/src/app/** | `page.tsx`, `api/` routes | Chat interface, visualizations |
| **ui/src/components/** | React components | UI building blocks |
| **data/** | JSON workspaces | Knowledge base storage |

</details>

---

## ğŸ”¬ Research

<div align="center">

This project implements research from:

[![arXiv](https://img.shields.io/badge/arXiv-2511.07587-b31b1b?style=for-the-badge&logo=arxiv)](https://arxiv.org/abs/2511.07587)

**"Functional Structure of Episodic Memory"**

</div>

### Foundational Research Papers

| Theory | Paper | Authors |
|--------|-------|---------|
| **Tolman-Eichenbaum Machine** | [The Tolman-Eichenbaum Machine: Unifying Space and Relational Memory through Generalization in the Hippocampal Formation](https://www.cell.com/cell/fulltext/S0092-8674(20)31388-X) | Whittington et al., 2020 |
| **Clone-Structured Cognitive Graphs** | [Clone-structured graph representations enable flexible learning and vicarious evaluation of cognitive maps](https://www.biorxiv.org/content/10.1101/770495v2.full.pdf) | George et al., 2021 |
| **Active Inference** | [Active Inference: A Process Theory](https://www.fil.ion.ucl.ac.uk/~karl/Active%20Inference%20A%20Process%20Theory.pdf) | Friston et al., 2017 |
| **Hyperdimensional Computing** | [Hyperdimensional Computing: An Introduction to Computing in Distributed Representation with High-Dimensional Random Vectors](https://www.rctn.org/vs265/kanerva09-hyperdimensional.pdf) | Kanerva, 2009 |
| **Global Workspace Theory** | [Global Workspace Theory of Consciousness](https://tilde.ini.uzh.ch/~kiper/Baars_1.pdf) | Baars, 1997 |

---

## ğŸ¤ Contributing

We welcome contributions! See our [Contributing Guidelines](CONTRIBUTING.md).

```bash
# Quick contribution workflow
git checkout -b feature/your-feature
# Make changes
pytest tests/
git commit -m "feat(module): description"
git push origin feature/your-feature
# Open Pull Request
```

<details>
<summary><b>ğŸ“‹ Contribution Areas</b></summary>
<br>

- ğŸ› **Bug fixes** - Help squash bugs
- âœ¨ **New features** - Add new capabilities
- ğŸ“š **Documentation** - Improve docs and examples
- ğŸ§ª **Tests** - Increase test coverage
- ğŸ¨ **UI/UX** - Enhance the frontend

</details>

---

## ğŸ“œ License

<div align="center">

MIT License - see [LICENSE](LICENSE) for details.

---

### Built by [Verridian AI](https://github.com/Verridian-ai)

*Cognitive AI for Legal Intelligence*

<br>

[![GitHub](https://img.shields.io/badge/GitHub-Verridian--ai-181717?style=for-the-badge&logo=github)](https://github.com/Verridian-ai)
[![Paper](https://img.shields.io/badge/Paper-arXiv-b31b1b?style=for-the-badge&logo=arxiv)](https://arxiv.org/abs/2511.07587)
[![Issues](https://img.shields.io/badge/Issues-Report-red?style=for-the-badge&logo=github)](https://github.com/Verridian-ai/Functional-Structure-of-Episodic-Memory/issues)
[![Discussions](https://img.shields.io/badge/Discussions-Join-purple?style=for-the-badge&logo=github)](https://github.com/Verridian-ai/Functional-Structure-of-Episodic-Memory/discussions)

---

**Proof of Concept** â€¢ Production-ready Architecture â€¢ Demonstration Data Scale

<br>

> *"The brain doesn't search for memories - it reconstructs them."*
>
> â€” Cognitive Neuroscience Principle

</div>
