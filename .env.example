# Verridian Legal AI - Environment Configuration
# ==============================================
# Copy this file to .env and fill in your values

# ============================================
# LLM API Configuration (Required)
# ============================================

# OpenRouter API Key (get from https://openrouter.ai)
OPENROUTER_API_KEY=sk-or-v1-your-key-here

# Optional: Direct Google AI access
# GOOGLE_AI_API_KEY=your-google-ai-key

# ============================================
# LangFuse Observability (Local Self-Hosted)
# ============================================

# After running docker compose up -d in docker/langfuse:
# 1. Go to http://localhost:3001
# 2. Create an account
# 3. Create a project
# 4. Get API keys from Settings > API Keys

LANGFUSE_PUBLIC_KEY=pk-lf-your-public-key
LANGFUSE_SECRET_KEY=sk-lf-your-secret-key
LANGFUSE_HOST=http://localhost:3001

# ============================================
# Data Paths
# ============================================

DATA_DIR=./data
CORPUS_DIR=./data/corpus
PROCESSED_DIR=./data/processed

# ============================================
# Model Configuration
# ============================================

# Embedding model (for vector search)
EMBEDDING_MODEL=BAAI/bge-m3

# LLM model (via OpenRouter)
# Gemini 2.0 Flash Experimental - FREE model, 1M context window
LLM_MODEL=google/gemini-2.0-flash-exp:free

# Temperature for generation
LLM_TEMPERATURE=0.7

# ============================================
# System Configuration
# ============================================

# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Enable debug mode
DEBUG=false

# Maximum concurrent LLM requests
MAX_CONCURRENT_REQUESTS=5

# ============================================
# Optional: Production Settings
# ============================================

# For production deployment:
# NODE_ENV=production
# NEXTAUTH_SECRET=your-production-secret-min-32-chars
# DATABASE_URL=postgresql://user:pass@host:port/db
